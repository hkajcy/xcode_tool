//
//  BufferTest.m
//  Test
//
//  Created by Liu Shanfeng on 11-6-8.
//  Copyright 2011 Vanceinfo. All rights reserved.
//

#import "eVoicePlayer.h"
#include <stdio.h>
#include <errno.h>
#include <stdlib.h>
#include <sys/stat.h>
#import <AVFoundation/AVAudioSession.h>
#import <AVFoundation/AVAudioPlayer.h>
#import <AudioToolbox/AudioServices.h>
#import <AudioToolbox/AudioConverter.h>
#include "eVoicePlayer.h"
#include "eVoice.h"
#import "Debug.h"
#import "eVoiceTimer.h"

#ifdef DOCIN_TARGET_WITHOUTEVOICE
#define TARGET_IPHONE_SIMULATOR 1
#endif

void AQBufferCallback(void *inUserData, AudioQueueRef inQ, AudioQueueBufferRef outQB);
void AQPropertyListenerProc(void *                  inUserData,
                            AudioQueueRef           inAQ,
                            AudioQueuePropertyID    inID);
extern int ttsInitialforDocin(const char* deviceCN,const char* deviceEN, int * nHandleret,  int nLangMode );

static eVoicePlayer* instance = nil;

@interface eVoicePlayer()

@property (nonatomic,retain) NSString* playingStr;
@property (nonatomic,assign) AQCallbackStruct* aqc;
@property (nonatomic,assign) pnWaveStruct* pnWave;
@property (nonatomic,assign) int mSynNum;
@property (nonatomic,assign) int mPlayNum;
@property (assign) volatile int roundCount;
@property (assign) int mFullNum;
@property (assign) volatile BOOL isExit;
@property (assign) volatile BOOL isNeedProducting;
@property (assign) volatile BOOL isPlaying;
@property (assign) volatile BOOL isStopSythe;  //转换退出标志
@property (assign) volatile BOOL isStopPlaying; //播放退出标志
@property (assign) NSCondition* productCondition;

@property (assign) int lastSynNum;
@property (assign) int tottalSynNum;
@property (assign) int tottalPlayNum;

@property (assign) volatile BOOL isProductingEnd;
@property (assign) int enqueueCount;

@property (assign) int changeVoiceNum;

- (void) resetData;
- (void) GenerateWave:(NSString*)txt;
- (void) ttsplay;
- (void) didFinishedSytheText;
- (void) didFinishedPlay;
- (void) checkIfNeedChangeVoice:(int)synNum;
- (void) changeVoiceModeWithManOrWoman:(int)vMode// 0 for man; 1 for woman
                        WithVoiceStyle:(int)vStyle// 0 是默认， 1 是普通话， 2 是粤语
                        WithVoiceSpeed:(float)vSpeed// 1.0 for normal, >1 quick <1 slow 
                   IsPlayingBackground:(BOOL)isBackGroundPlay;


@end

@implementation eVoicePlayer

@synthesize enqueueCount;
@synthesize isProductingEnd;
@synthesize isPlaying;
@synthesize isExit;

@synthesize lastSynNum;
@synthesize tottalSynNum;
@synthesize tottalPlayNum;

@synthesize roundCount;
@synthesize playSoundDelegate;
@synthesize playingStr;
@synthesize mSynNum;
@synthesize mPlayNum;
@synthesize mFullNum;
@synthesize isNeedProducting;
@synthesize aqc;
@synthesize pnWave;
@synthesize productCondition;
@synthesize isStopSythe;
@synthesize isStopPlaying;
@synthesize voiceMaleOrFamale;
@synthesize voiceStyle;
@synthesize voiceSpeed;
@synthesize isBackgroundPlay;
@synthesize changeVoiceDelegate;
@synthesize changeVoiceNum;
@synthesize lastSynNumArray;
@synthesize operationQueue;
@synthesize isPausing;

#pragma mark-
#pragma mark --- Initial---
- (void) InitialSysthe
{
    for (int i = 0; i < sythePipeNumber; i++) 
    {
		[eVoicePlayer sharedInstance].pnWave[i].nLength = 0;
		[eVoicePlayer sharedInstance].pnWave[i].isValid = 0;
		[eVoicePlayer sharedInstance].pnWave[i].pnWav = (unsigned short*)malloc(sizeof(unsigned short)*CONSTSIZE);
	}
}

- (void) setIsBackgroundPlay:(BOOL)isBackGroundPlay;
{
    isBackgroundPlay = isBackGroundPlay;
    
  
    if (isBackGroundPlay)
    {
        AVAudioSession* audioSession = [AVAudioSession sharedInstance];
        [audioSession setCategory:AVAudioSessionCategoryPlayback error:nil];
        [audioSession setActive:YES error:nil];
    }
    else
    {
        AVAudioSession* audioSession = [AVAudioSession sharedInstance];
        [audioSession setCategory:AVAudioSessionCategoryAmbient error:nil];
        [audioSession setActive:YES error:nil];
    }
}

void MyAudioQueuePropertyListenerProc (void                  *inUserData,
                                       AudioQueueRef         inAQ,
                                       AudioQueuePropertyID  inID
                                       )
{
//    int isRunning;
//    UInt32 ioDataSize = sizeof(isRunning);
//    AudioQueueGetProperty(inAQ,kAudioQueueProperty_IsRunning , &isRunning, &ioDataSize);
//    
//    CMLog(@"%d", isRunning);
}

- (void) beginInterruption
{
    @synchronized (self)
    {
        AVAudioSession* audioSession = [AVAudioSession sharedInstance];
        if (audioSession.delegate == self)
        {
        }
    }
    
}
- (void) endInterruption
{
    @synchronized (self)
    {
        AVAudioSession* audioSession = [AVAudioSession sharedInstance];
        if (audioSession.delegate == self)
        {
            if(!isPausing)
            {
                [self startPlay];
                isPausing = NO;
            }
            
        }
    }
}

- (void) InitialPlaySound
{
    aqc->mDataFormat.mSampleRate = SAMPLE_RATE; 
    aqc->mDataFormat.mFormatID = kAudioFormatLinearPCM;
    aqc->mDataFormat.mFormatFlags =
    kLinearPCMFormatFlagIsSignedInteger
    | kAudioFormatFlagIsPacked; 
    aqc->mDataFormat.mBytesPerPacket = 4; 
    aqc->mDataFormat.mFramesPerPacket = 1; 
    aqc->mDataFormat.mBytesPerFrame = 4; 
    aqc->mDataFormat.mChannelsPerFrame = 2;
    aqc->mDataFormat.mBitsPerChannel = 16; 
    aqc->frameCount = FRAME_COUNT; 
    
    aqc->playPtr = 0;
    
    aqc->frameCount = CONSTSIZE / BYTES_PER_SAMPLE;
    aqc->sampleLen = aqc->frameCount * 2;
    
    AudioQueueNewOutput(&aqc->mDataFormat,
                        AQBufferCallback,
                        self,
                        NULL, 
                        kCFRunLoopCommonModes,//
                        0, 
                        &aqc->queue);
    
    int bufferSize = aqc->frameCount * aqc->mDataFormat.mBytesPerFrame;
    
    for (int i = 0;i < AUDIO_BUFFERS;i++)
    {
        AudioQueueAllocateBuffer(aqc->queue, bufferSize, &aqc->mBuffers[i]);
    }
    
    AVAudioSession* audioSession = [AVAudioSession sharedInstance];
    audioSession.delegate = self;
    
    AudioQueueAddPropertyListener(aqc->queue,kAudioQueueProperty_IsRunning,MyAudioQueuePropertyListenerProc,self);
    
    CMLog(@"InitialPlaySound end");
}

- (void) InitialData
{
    [[UIApplication sharedApplication] beginReceivingRemoteControlEvents];
    
    instance = self;
    synHandle = @"synHandle";    
    
    productCondition = [[NSCondition alloc] init];
    
    pnWave = malloc(sizeof(pnWaveStruct) * sythePipeNumber);
    aqc = malloc(sizeof(AQCallbackStruct));
    
    lastSynNum = 0;
    roundCount = 0;
    
    NSUserDefaults* userDefaults = [NSUserDefaults standardUserDefaults];

    voiceMaleOrFamale = [userDefaults integerForKey:@"voiceMaleOrFamale"];
    voiceStyle = [userDefaults integerForKey:@"voiceStyle"];
    NSString* voiceSpeedStr = [userDefaults stringForKey:@"voiceSpeed"];
    if (voiceSpeedStr == nil)
    {
        [userDefaults setFloat:VOICEPLAYSPEEDDEFAULTVALUE forKey:@"voiceSpeed"];
    }
    voiceSpeed = [userDefaults floatForKey:@"voiceSpeed"];
    if (voiceSpeed > VOICEPLAYSPEEDMAXVALUE
        || voiceSpeed < VOICEPLAYSPEEDMINVALUE)
    {
        voiceSpeed = VOICEPLAYSPEEDDEFAULTVALUE;
        [userDefaults setFloat:VOICEPLAYSPEEDDEFAULTVALUE forKey:@"voiceSpeed"];
    }
    
    NSString* isBackgroundPlayStr = [userDefaults stringForKey:@"isBackgroundPlay"];
    if (isBackgroundPlayStr == nil)
    {
        [userDefaults setBool:YES forKey:@"isBackgroundPlay"];
    }
    isBackgroundPlay = [userDefaults boolForKey:@"isBackgroundPlay"];
    
    self.operationQueue = [[[NSOperationQueue alloc] init] autorelease];
    [operationQueue setMaxConcurrentOperationCount:1];
    
    [self resetData];
    
    [self InitialSysthe];
    [self InitialPlaySound];
    
    [self changeVoiceModeWithManOrWoman:voiceMaleOrFamale
                      WithVoiceStyle:voiceStyle
                      WithVoiceSpeed:voiceSpeed
                 IsPlayingBackground:isBackgroundPlay];
    
}

- (id) init
{
    self = [super init];
    if(self)
    {
        [self InitialData];
    }
    return self;
}

- (void) resetData
{
    @synchronized (self)
    {
        SAFE_RELEASE(lastSynNumArray)
        lastSynNumArray = [[NSMutableArray alloc] initWithCapacity:0];
        
        self.isStopSythe = NO;
        self.isStopPlaying = NO;
        self.isNeedProducting = NO;
        self.isExit = NO;
        self.isPlaying = NO;
        self.lastSynNum = 0;//-4的原因就是让这个lastSynNum不起作用。
        self.tottalSynNum = 0;
        self.tottalPlayNum = 0;
        
        roundCount = 0;
        mPlayNum = 0;
        mSynNum = 0;
        mFullNum = 0;
        
        for (int i = 0; i < sythePipeNumber; i++) 
        {
            pnWave[i].nLength = 0;
            pnWave[i].isValid = 0;
        }
    }
}

+ (eVoicePlayer*) sharedInstance
{
    @synchronized(self)
    {
        if(instance == nil)
        {
            instance = [[eVoicePlayer alloc] init];
        }
    }
    return instance;
}

#pragma mark-
#pragma mark --- callBack threads---
void SynCallBack(void *pWav, int nLength, int nStopFlat)
{
    NSAutoreleasePool* pool = [[NSAutoreleasePool alloc] init];
    eVoicePlayer* evPlayer = [eVoicePlayer sharedInstance];
    if ([evPlayer isStopSythe] || [evPlayer isExit]) 
    {
        SAFE_RELEASE(pool)
        return;
    }
    
	if (nLength >= 0)
	{	
    
        //如果要放入的位置的buffer还没有播放就等待
        while (evPlayer.pnWave[evPlayer.mSynNum].isValid ==1)
        {
            if ([evPlayer isStopSythe] || [evPlayer isExit]) 
            {
                SAFE_RELEASE(pool)
                return;
            }
            sleep(0);
        }   
                
        evPlayer.pnWave[evPlayer.mSynNum].nLength = nLength;
        
        if (pWav)
        {
            memcpy(evPlayer.pnWave[evPlayer.mSynNum].pnWav, pWav, nLength);
        }
        else
        {
            memset(evPlayer.pnWave[evPlayer.mSynNum].pnWav, 0, sizeof(unsigned short)*CONSTSIZE);
        }
        
        evPlayer.pnWave[evPlayer.mSynNum].isValid = 1;
        evPlayer.mSynNum++;
        evPlayer.tottalSynNum++;
        if (evPlayer.mSynNum == sythePipeNumber) 
        {
            evPlayer.mSynNum = 0;
        }
        
        evPlayer.mFullNum++;
        
        
        //如果没有播放，就唤醒它
        if (!evPlayer.isPlaying
            && evPlayer.mFullNum >= AUDIO_BUFFERS
            )
        {
            CMLog(@"初始化播放");
            [evPlayer ttsplay];
        }
	}
    
    SAFE_RELEASE(pool)
}

void AQBufferCallback(void *inUserData, AudioQueueRef inQ, AudioQueueBufferRef outQB)
{
    NSAutoreleasePool* pool = [[NSAutoreleasePool alloc] init];
    eVoicePlayer* evPlayer = (eVoicePlayer*)inUserData;
    evPlayer.enqueueCount--;
    
    if (evPlayer.tottalPlayNum >= evPlayer.changeVoiceNum && evPlayer.changeVoiceNum != -1)
    {
        [evPlayer.changeVoiceDelegate didFinishedChange];
        evPlayer.changeVoiceNum = -1;
    }
    
    if (evPlayer.isStopPlaying)
    {
        //而且这是最后一个返回的callBack
        if (evPlayer.enqueueCount == 0)
        {
            evPlayer.isPlaying = NO;
            AudioQueueStop(evPlayer.aqc->queue, YES);
        
            //有可能之前没有调用。
            [evPlayer.changeVoiceDelegate didFinishedChange];
            evPlayer.changeVoiceNum = -1;
        }
    }
    else 
    {
        @synchronized (evPlayer)
        {
            AQCallbackStruct *aqc = evPlayer.aqc;
            short *coreAudioBuffer = (short*) outQB->mAudioData;;
            short sample = 0;
            
            if (evPlayer.mFullNum <= 0)
            {
                if (evPlayer.enqueueCount == 0)
                {
                    evPlayer.isPlaying = NO;
                    
                    //播完了之后还有没有被移除的队列。这个时候需要再调用 didFinishedPlay
                    if ([evPlayer.lastSynNumArray count])
                    {
                        [evPlayer.lastSynNumArray removeObjectAtIndex:0];
                        [evPlayer didFinishedPlay];
                    }
                }
            }
            else
                //如果缓存内没有数据需要播放
            {
                //CMLog(@"把声音数据推入队列中;");
                //把声音数据推入队列中 start
                //outQB->mAudioDataByteSize = 2*evPlayer.pnWave[evPlayer.mPlayNum].nLength;
                
                outQB->mAudioDataByteSize = 4 * aqc->frameCount;
                
                if (aqc->frameCount > 0)
                {
                    for (int i = 0; i < CONSTSIZE; i+=2) 
                    {
                        assert((int)aqc->playPtr >= 0);
                        if(aqc->playPtr >= evPlayer.pnWave[evPlayer.mPlayNum].nLength/2)
                        {
                            sample = 0;
                        }
                        else
                            //sample = 0;
                            sample = evPlayer.pnWave[evPlayer.mPlayNum].pnWav[aqc->playPtr];
                        //			
                        coreAudioBuffer[i]= sample;//Left Channel Data
                        coreAudioBuffer[i+1]= sample;//Right Channel Data
                        aqc->playPtr++;
                    }
                }
                
                AudioQueueEnqueueBuffer(inQ, outQB, 0, NULL);
                evPlayer.tottalPlayNum++;
                evPlayer.enqueueCount++;
                //把声音数据推入到队列中 end
                evPlayer.mFullNum--;										//剩下的bufffer个数
                
                evPlayer.pnWave[evPlayer.mPlayNum].isValid = 0;
                aqc->playPtr = 0;								//指针复位，指向下一个buffer的起始数据
                evPlayer.mPlayNum++;
                if (evPlayer.mPlayNum == sythePipeNumber) 
                {
                    evPlayer.mPlayNum = 0;								//播放的指针移动到下一个buffer
                }
                
                int lastSynNum = 65535;
                if ([evPlayer.lastSynNumArray count])
                {
                    lastSynNum = [[evPlayer.lastSynNumArray objectAtIndex:0] intValue];
                }
                
                if (evPlayer.tottalPlayNum  >= lastSynNum + AUDIO_BUFFERS -1)
                {
                    [evPlayer didFinishedPlay];
                    [evPlayer.lastSynNumArray removeObjectAtIndex:0];
                }
            }
        }
    }
    SAFE_RELEASE(pool)
}

- (void) didFinishedSytheText
{
    [(NSObject*)playSoundDelegate performSelectorOnMainThread:@selector(didFinishedSytheText) withObject:nil waitUntilDone:NO];
}

- (void) didFinishedPlay
{
    [(NSObject*)playSoundDelegate performSelectorOnMainThread:@selector(didFinishPlaySound) withObject:nil waitUntilDone:NO];
}

-(void)ttsplay
{
	NSAutoreleasePool *pool = [[NSAutoreleasePool alloc] init];
    
    self.isPlaying = YES;
    
    for (int i = 0; i< AUDIO_BUFFERS; i++)
    {
        self.enqueueCount++;
        AQBufferCallback(self, self.aqc->queue,self.aqc->mBuffers[i]);
    }

    UInt32 isRunning;
    UInt32 size = sizeof(isRunning);
    AudioQueueGetProperty(self.aqc->queue, kAudioQueueProperty_IsRunning, &isRunning, &size);
    if (!isRunning)
    {
        AudioQueueStart(self.aqc->queue, NULL);
    }
	
    SAFE_RELEASE(pool)
}

- (void) GenerateWave:(NSString*)txt
{
    NSAutoreleasePool* pool = [[NSAutoreleasePool alloc] init];
    
    NSString *szUTFText = txt;
    NSStringEncoding enc = CFStringConvertEncodingToNSStringEncoding(kCFStringEncodingGB_18030_2000);
    
	const char *outstr = nil;
    int nextstr ;
    nextstr = 0;
	outstr = [szUTFText cStringUsingEncoding:enc];
    
    @synchronized (synHandle)
    {
        self.isProductingEnd = NO;
#if !TARGET_IPHONE_SIMULATOR
        NSAutoreleasePool* pool = [[NSAutoreleasePool alloc] init];
        ttsSynthesis(nHandle, outstr,NULL, &nWaveLen, &nextstr,SynCallBack);
        SAFE_RELEASE(pool)
#endif
        self.isProductingEnd = YES;
    }

    
    //判断是否需要改变声音
    [self checkIfNeedChangeVoice:self.tottalSynNum];
    

    //说明没有播放
    if (self.lastSynNum == self.tottalSynNum)
    {
        //没有播放数据的话，手动添加一个0数据
        SynCallBack(NULL, 0, 0);
        SynCallBack(NULL, 0, 0);
        SynCallBack(NULL, 0, 0);
    }
    
    self.lastSynNum = self.tottalSynNum;
    
    @synchronized (self)
    {
        [lastSynNumArray addObject:[NSNumber numberWithInt:self.lastSynNum]];
    }
    
    if (!self.isPlaying)
    {
        [self ttsplay];
    }
    
    @synchronized (self)
    {
        //如果不是退出条件
        if (!isStopSythe && !isExit)
        {
            //继续解析。
            [self didFinishedSytheText];
        }
    }
    SAFE_RELEASE(pool)
}

- (void) saveConfig
{
    NSUserDefaults* userDefaults = [NSUserDefaults standardUserDefaults];
    [userDefaults setInteger:voiceMaleOrFamale  forKey:@"voiceMaleOrFamale"];
    [userDefaults setInteger:voiceStyle  forKey:@"voiceStyle"];
    [userDefaults setFloat:voiceSpeed forKey:@"voiceSpeed"];
    [userDefaults setBool:isBackgroundPlay forKey:@"isBackgroundPlay"];
    [userDefaults synchronize]; 
}

#pragma mark-
#pragma mark --- setVoice---
- (void) changeVoiceModeWithManOrWoman:(int)vMode// 0 for man; 1 for woman
                     WithVoiceStyle:(int)vStyle// 0 是默认， 1 是普通话， 2 是粤语
                     WithVoiceSpeed:(float)vSpeed
                IsPlayingBackground:(BOOL)isBackGroundPlay
{
    @synchronized (synHandle)
    {
        [self setIsBackgroundPlay:isBackGroundPlay];
        
        NSString *PathCN = nil;
        NSString *PathEN = nil;
        if (vMode)
        {
            PathEN = [[NSBundle mainBundle] pathForResource:@"Jack" ofType:@"dat"];
            switch (vStyle)
            {
                case VoiceStyle_Putonghua:
                    PathCN = [[NSBundle mainBundle] pathForResource:@"xiaoyan" ofType:@"dat"];
                    break;
                case VoiceStyle_Yueyu:
                    PathCN = [[NSBundle mainBundle] pathForResource:@"xiaowang" ofType:@"dat"];
                    break;
                default:
                    PathCN = [[NSBundle mainBundle] pathForResource:@"xiaotian" ofType:@"dat"];
                    break;
            }
        }
        else
        {
            PathEN = [[NSBundle mainBundle] pathForResource:@"Rose" ofType:@"dat"];
            switch (vStyle)
            {
                case VoiceStyle_Putonghua:
                    PathCN = [[NSBundle mainBundle] pathForResource:@"xiaoxu" ofType:@"dat"];
                    
                    break;
                case VoiceStyle_Yueyu:
                    PathCN = [[NSBundle mainBundle] pathForResource:@"xiaowei" ofType:@"dat"];
                    break;
                default:
                    PathCN = [[NSBundle mainBundle] pathForResource:@"xiaoyan" ofType:@"dat"];
                    break;
            }
        }
        
        const char *deviceCN;
        deviceCN = [PathCN UTF8String];
        
        const char *deviceEN;
        deviceEN = [PathEN UTF8String];	
        CMLog(@"TTSInitialForDocin:\n");
        if (nHandle)
        {
#if !TARGET_IPHONE_SIMULATOR
            ttsClose(nHandle);
#endif
        }
        

#if !TARGET_IPHONE_SIMULATOR
        int ret = ttsInitialforDocin(deviceCN,deviceEN,&nHandle,voiceStyle);
        
        CMLog(@"nHandle = %d",nHandle);
        if(ret != NO)
        {
            printf("ERROR:cannot initialize the system!\n");
            assert(0) ;
        }
//        更改音量有一个接口，可以直接在初始化ttsInitialforDocin之后直接调用  int ttsSetVolume(int nTTSHandle,float fVolume) ,fVolume的值域是0.5---1.75，默认大小是1.0
        ttsSetVolume(nHandle, 1.70);
#endif
        
#if !TARGET_IPHONE_SIMULATOR 
        assert(vSpeed <= VOICEPLAYSPEEDMAXVALUE);
        assert(vSpeed >= VOICEPLAYSPEEDMINVALUE);
        ttsSetSpeed(nHandle, vSpeed);
#endif
        
        [self saveConfig];
        
        isNeedChangeVoice = NO;
    }
}

-(void) checkIfNeedChangeVoice:(int)synNum
{
    if (isNeedChangeVoice)
    {
        changeVoiceNum = synNum;
        [self changeVoiceModeWithManOrWoman:voiceMaleOrFamale
                             WithVoiceStyle:voiceStyle
                             WithVoiceSpeed:voiceSpeed
                        IsPlayingBackground:isBackgroundPlay];
    }
}
- (void) setVoiceModeWithManOrWoman:(int)vMode// 0 for man; 1 for woman
                     WithVoiceStyle:(int)vStyle// 0 是默认， 1 是普通话， 2 是粤语
                     WithVoiceSpeed:(float)vSpeed// 1.0 for normal, >1 quick <1 slow 
                IsPlayingBackground:(BOOL)isBackGroundPlay
{    
    @synchronized (synHandle)
    {
        voiceMaleOrFamale = vMode;
        voiceStyle = vStyle;
        voiceSpeed = vSpeed;
        isBackgroundPlay = isBackGroundPlay;
        
        if (self.isProductingEnd)
        {
            isChangingVoice = YES;
            [self changeVoiceModeWithManOrWoman:vMode
                                 WithVoiceStyle:vStyle
                                 WithVoiceSpeed:vSpeed
                            IsPlayingBackground:isBackGroundPlay];
            isChangingVoice = NO;
            [changeVoiceDelegate didFinishedChange];
        }
        else
        {
            isNeedChangeVoice = YES;
        }
    }
}

#pragma mark-
#pragma mark --- playText---
- (void) playText:(NSString*)txt stopOldPlay:(BOOL)stopOldPlay
{
    NSAutoreleasePool* pool = [[NSAutoreleasePool alloc] init];
    
    //if need stop old play
    if (stopOldPlay)
    {
        [self stopPlayForPlayingNewText];
    }
    
    self.playingStr = txt;
    
    NSInvocationOperation* operation = [[[NSInvocationOperation alloc] initWithTarget:self 
                                                                             selector:@selector(GenerateWave:) 
                                                                               object:playingStr] autorelease];

    [self.operationQueue addOperation:operation];
    
    SAFE_RELEASE(pool)
}

- (void) startPlay
{
    AVAudioSession* audioSession = [AVAudioSession sharedInstance];
    [audioSession setCategory:AVAudioSessionCategoryPlayback error:nil];
    [audioSession setActive:YES error:nil];
    AudioQueueStart([eVoicePlayer sharedInstance].aqc->queue, NULL);
    
    CMLog(@"startPlay");
}

- (void) pauseOrResume
{
    if(isPausing)
    {
        AudioQueueStart([eVoicePlayer sharedInstance].aqc->queue, NULL);
        isPausing = NO;
    }
    else
    {
        AudioQueuePause([eVoicePlayer sharedInstance].aqc->queue);
        isPausing = YES;
    }
}

// Respond to remote control events
- (void) remoteControlReceivedWithEvent: (UIEvent *) receivedEvent {
    
#ifndef DOCIN_TARGET_WITHOUTEVOICE
    if (receivedEvent.type == UIEventTypeRemoteControl)
    {
        switch (receivedEvent.subtype) 
        {
            case UIEventSubtypeRemoteControlTogglePlayPause:
                [[eVoicePlayer sharedInstance] pauseOrResume];
                break;
                
            case UIEventSubtypeRemoteControlPreviousTrack:
                break;
                
            case UIEventSubtypeRemoteControlNextTrack:
                break;
                
            default:
                break;
        }
    }
#endif
    
}

#pragma mark-
#pragma mark --- stopPlay---
- (void) stopPlayForPlayingNewText
{    
    //停止生产
    self.isStopSythe = YES;
    self.isStopPlaying = YES;
    
    [self.operationQueue cancelAllOperations];
    [self.operationQueue waitUntilAllOperationsAreFinished];
    
#if !TARGET_IPHONE_SIMULATOR
    ttsStop(nHandle);
#endif
    
    while (self.isPlaying)
    {
        sleep(0);
    }
    
    [self resetData];
    CMLog(@"stopPlayForPlayingNewText");
}

- (void) stopSystheThread
{  
    [self.operationQueue cancelAllOperations];
    [self.operationQueue waitUntilAllOperationsAreFinished];
}

- (void) freeMomery
{
#if !TARGET_IPHONE_SIMULATOR
    ttsClose(nHandle);
    nHandle = 0;
#endif
    for (int i = 0;i < AUDIO_BUFFERS;i++)
    {
        AudioQueueFreeBuffer(aqc->queue, aqc->mBuffers[i]);
    }
    
    for (int i = 0; i < sythePipeNumber; i++) 
    {
		free(pnWave[i].pnWav);
	}
    
    free(pnWave);
    free(aqc);

    SAFE_RELEASE(playingStr)
    SAFE_RELEASE(productCondition)
    SAFE_RELEASE(operationQueue)
    SAFE_RELEASE(lastSynNumArray)
    [self release];
}

- (void) stopPlay
{
    if(instance != nil)
    {
        [[UIApplication sharedApplication] endReceivingRemoteControlEvents];
        
        @synchronized (self)
        {
            AVAudioSession* audioSession = [AVAudioSession sharedInstance];
            audioSession.delegate = nil;
        }
        
        
        isStopSythe = YES;
        isExit = YES;
        isStopPlaying = YES;
        [self stopSystheThread];
        
        [playSoundDelegate didStopPlaySound];
        [changeVoiceDelegate didFinishedChange];
        
        [self freeMomery];
        
        
        instance = nil;
    }
}

- (void)setQueue:(AudioQueueRef)ref toVolume:(float)newValue 
{
    AudioQueueSetParameter(ref, kAudioQueueParam_Volume, newValue);
}


- (void) increaseSound:(id)sender
{
    float volumeData = 0;
    UInt32 volumeDataSize = 0;
    AudioQueueGetProperty( [eVoicePlayer sharedInstance].aqc->queue,
                                        kAudioQueueParam_Volume,
                                        &volumeData,
                                        &volumeDataSize);
    [self setQueue:[eVoicePlayer sharedInstance].aqc->queue toVolume:1.0];
}

- (void) decreaseSound:(id)sender
{
    float volumeData = 0;
    UInt32 volumeDataSize = 0;
    AudioQueueGetProperty( [eVoicePlayer sharedInstance].aqc->queue,kAudioQueueParam_Volume,&volumeData,&volumeDataSize) ;
    [self setQueue:[eVoicePlayer sharedInstance].aqc->queue toVolume:0.0];    
}

- (void)dealloc
{
    [super dealloc];
}

@end
